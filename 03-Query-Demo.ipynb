{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EcoMetricx â€” Retrieval Demo (MVP)\n",
        "\n",
        "This notebook demos the early query system pipeline:\n",
        "- Load normalized documents (Phase 2 output)\n",
        "- If missing, auto-run normalization to generate it\n",
        "- Chunk into retrieval units (simple, page-aware)\n",
        "- Build a TF-IDF index (CPU-only)\n",
        "- Run keyword/semantic-ish search and show citations\n",
        "\n",
        "Run cells top-to-bottom to try queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: /root/Programming Projects/Personal/EcoMetricx\n",
            "Current run_id: 20250903_093826\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import json, subprocess, sys\n",
        "from datetime import datetime\n",
        "\n",
        "project_root = Path.cwd()\n",
        "run_id_path = project_root / '.current_run_id'\n",
        "run_id = run_id_path.read_text().strip() if run_id_path.exists() else None\n",
        "print('Project root:', project_root)\n",
        "print('Current run_id:', run_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Documents loaded: 1\n",
            "Document id: emx:visual_extraction:6a55e73ff2d9\n"
          ]
        }
      ],
      "source": [
        "# Ensure normalized documents exist; auto-run normalization if missing\n",
        "norm_base = project_root / 'data' / 'normalized' / 'visual_extraction'\n",
        "if run_id is None or not (norm_base / run_id / 'documents.jsonl').exists():\n",
        "\tprint('Normalized documents missing; running normalization script...')\n",
        "\tret = subprocess.run([sys.executable, str(project_root / 'scripts' / 'normalize_to_documents.py')], capture_output=True, text=True)\n",
        "\tprint(ret.stdout or ret.stderr)\n",
        "\t# Refresh run_id if it was None\n",
        "\tif run_id is None and run_id_path.exists():\n",
        "\t\trun_id = run_id_path.read_text().strip()\n",
        "\n",
        "norm_doc = norm_base / run_id / 'documents.jsonl'\n",
        "assert norm_doc.exists(), f'Missing {norm_doc}'\n",
        "rows = [json.loads(l) for l in norm_doc.read_text(encoding='utf-8').splitlines() if l.strip()]\n",
        "print('Documents loaded:', len(rows))\n",
        "print('Document id:', rows[0]['document_id'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create simple chunks (page-aware)\n",
        "We split the document text by pages into retrieval units and attach page numbers and a section path placeholder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunks loaded: 1\n",
            "Sample chunk: {'parent_document_id': 'emx:visual_extraction:6a55e73ff2d9', 'page_num': 1, 'section_path': 'page/1'}\n"
          ]
        }
      ],
      "source": [
        "chunk_file = project_root / 'data' / 'chunks' / 'visual_extraction' / run_id / 'chunks.jsonl'\n",
        "if not chunk_file.exists():\n",
        "\tprint('Chunks missing; running chunking script...')\n",
        "\tret = subprocess.run([sys.executable, str(project_root / 'scripts' / 'chunk_and_redact.py')], capture_output=True, text=True)\n",
        "\tprint(ret.stdout or ret.stderr)\n",
        "\n",
        "chunks = [json.loads(l) for l in chunk_file.read_text(encoding='utf-8').splitlines() if l.strip()]\n",
        "print('Chunks loaded:', len(chunks))\n",
        "print('Sample chunk:', {k: chunks[0][k] for k in ('parent_document_id','page_num','section_path')})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunks: 2\n",
            "Home Energy Report: electricity March report Account number: 954137 Service address: 1627 Tulip Lane Dear JILL DOE, here is your usage analysis for March. Your electric use: 18% more than similar near...\n"
          ]
        }
      ],
      "source": [
        "doc = rows[0]\n",
        "chunks = []\n",
        "for p in doc.get('pages', []):\n",
        "\ttext = p.get('text','').strip()\n",
        "\tif not text:\n",
        "\t\tcontinue\n",
        "\tchunks.append({\n",
        "\t\t'chunk_index': len(chunks),\n",
        "\t\t'page_num': p.get('page_number', 0),\n",
        "\t\t'parent_document_id': doc['document_id'],\n",
        "\t\t'section_path': f\"page/{p.get('page_number', 0)}\",\n",
        "\t\t'text': text\n",
        "\t})\n",
        "print('Chunks:', len(chunks))\n",
        "print(chunks[0]['text'][:200] + ('...' if len(chunks[0]['text'])>200 else ''))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build TF-IDF index\n",
        "We use scikit-learn's `TfidfVectorizer` to index chunk texts for quick keyword/semantic-ish search.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index shape: (2, 135)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "corpus = [c['text'] for c in chunks]\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print('Index shape:', X.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Embeddings-based retrieval (BGE-small)\n",
        "We use FastEmbed with `BAAI/bge-small-en-v1.5` to embed chunks and queries, then perform cosine similarity search. Falls back to TF-IDF if unavailable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings ready: /root/Programming Projects/Personal/EcoMetricx/data/index/pgvector/20250903_093826/embeddings.jsonl\n",
            "Model: BAAI/bge-small-en-v1.5 dim: 384\n"
          ]
        }
      ],
      "source": [
        "# Ensure embeddings exist; auto-generate if missing (auto-install fastembed)\n",
        "from importlib import util as _iu\n",
        "\n",
        "emb_dir = project_root / 'data' / 'index' / 'pgvector' / run_id\n",
        "emb_file = emb_dir / 'embeddings.jsonl'\n",
        "manifest_file = emb_dir / 'index_manifest.json'\n",
        "\n",
        "# Ensure fastembed is available in this kernel\n",
        "if _iu.find_spec('fastembed') is None:\n",
        "\tprint('Installing fastembed in current kernel...')\n",
        "\t_ = subprocess.run([sys.executable, '-m', 'pip', 'install', 'fastembed', '--quiet'], text=True)\n",
        "\n",
        "# Generate embeddings if missing\n",
        "if not emb_file.exists():\n",
        "\tprint('Embeddings missing; generating...')\n",
        "\tret = subprocess.run([sys.executable, str(project_root / 'scripts' / 'embed_chunks.py')], capture_output=True, text=True)\n",
        "\tprint(ret.stdout or ret.stderr)\n",
        "\n",
        "if emb_file.exists():\n",
        "\tprint('Embeddings ready:', emb_file)\n",
        "\tmanifest = json.loads(manifest_file.read_text())\n",
        "\tprint('Model:', manifest.get('model'), 'dim:', manifest.get('embedding_dim'))\n",
        "else:\n",
        "\tprint('Embeddings not available; search will use TF-IDF fallback.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding matrix: (1, 384)\n"
          ]
        }
      ],
      "source": [
        "# Build in-memory embedding matrix if available\n",
        "import numpy as np\n",
        "\n",
        "emb_records = []\n",
        "if emb_file.exists():\n",
        "\tfor line in emb_file.read_text().splitlines():\n",
        "\t\tif not line.strip():\n",
        "\t\t\tcontinue\n",
        "\t\tr = json.loads(line)\n",
        "\t\temb_records.append(r)\n",
        "\tE = np.vstack([np.array(r['embedding_vector'], dtype=np.float32) for r in emb_records]) if emb_records else None\n",
        "\tid_to_idx = {r['chunk_id']: i for i, r in enumerate(emb_records)}\n",
        "\tprint('Embedding matrix:', E.shape if E is not None else None)\n",
        "else:\n",
        "\tE = None\n",
        "\tid_to_idx = {}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize chunk IDs (safety)\n",
        "Ensure every chunk has a `chunk_id` and build a lookup by id. This prevents KeyError if earlier cells created temporary chunks without IDs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique chunk ids: 2\n"
          ]
        }
      ],
      "source": [
        "# Ensure each chunk has a stable chunk_id and build lookup\n",
        "for i, c in enumerate(chunks):\n",
        "\tif 'chunk_id' not in c:\n",
        "\t\tc['chunk_id'] = f\"{c['parent_document_id']}:c{c.get('chunk_index', i)}\"\n",
        "chunk_by_id = {c['chunk_id']: c for c in chunks}\n",
        "print('Unique chunk ids:', len(chunk_by_id))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7733845710754395 emx:visual_extraction:6a55e73ff2d9 page 0\n",
            "Home Energy Report: electricity March report Account number: 954137 Service address: 1627 Tulip Lane Dear JILL DOE, here is your usage analysis for March. Your electric use: 18% more than similar nearby homes You TT A bove Similar nearby ho...\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# Override search_embedded to use chunk_by_id\n",
        "import numpy as np\n",
        "\n",
        "def search_embedded(query: str, k: int = 3):\n",
        "\tif E is None:\n",
        "\t\tprint('Embeddings not loaded; falling back to TF-IDF search()')\n",
        "\t\treturn search(query, k)\n",
        "\tfrom fastembed import TextEmbedding\n",
        "\temb = TextEmbedding('BAAI/bge-small-en-v1.5')\n",
        "\tqv = np.array(list(emb.embed([query]))[0], dtype=np.float32)\n",
        "\tqv = qv / (np.linalg.norm(qv) + 1e-9)\n",
        "\tEv = E / (np.linalg.norm(E, axis=1, keepdims=True) + 1e-9)\n",
        "\tscores = Ev @ qv\n",
        "\tidxs = scores.argsort()[-k:][::-1]\n",
        "\tresults = []\n",
        "\tfor idx in idxs:\n",
        "\t\tchunk_id = emb_records[idx]['chunk_id']\n",
        "\t\tc = chunk_by_id.get(chunk_id)\n",
        "\t\tif not c:\n",
        "\t\t\tcontinue\n",
        "\t\tresults.append({\n",
        "\t\t\t'score': float(scores[idx]),\n",
        "\t\t\t'document_id': c['parent_document_id'],\n",
        "\t\t\t'page_num': c['page_num'],\n",
        "\t\t\t'section_path': c['section_path'],\n",
        "\t\t\t'snippet': c['text'][:240] + ('...' if len(c['text'])>240 else '')\n",
        "\t\t})\n",
        "\treturn results\n",
        "\n",
        "# Demo\n",
        "for r in search_embedded('energy savings tips'):\n",
        "\tprint(r['score'], r['document_id'], f\"page {r['page_num']}\")\n",
        "\tprint(r['snippet'])\n",
        "\tprint('---')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique chunk ids: 2\n"
          ]
        }
      ],
      "source": [
        "# Backfill chunk_id if missing and build map\n",
        "for i, c in enumerate(chunks):\n",
        "\tif 'chunk_id' not in c:\n",
        "\t\tc['chunk_id'] = f\"{c['parent_document_id']}:c{c.get('chunk_index', i)}\"\n",
        "chunk_by_id = {c['chunk_id']: c for c in chunks}\n",
        "print('Unique chunk ids:', len(chunk_by_id))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7733845710754395 emx:visual_extraction:6a55e73ff2d9 page 0\n",
            "Home Energy Report: electricity March report Account number: 954137 Service address: 1627 Tulip Lane Dear JILL DOE, here is your usage analysis for March. Your electric use: 18% more than similar nearby homes You TT A bove Similar nearby ho...\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# Embedding-backed search; falls back to TF-IDF\n",
        "\n",
        "def search_embedded(query: str, k: int = 3):\n",
        "\tif E is None:\n",
        "\t\tprint('Embeddings not loaded; falling back to TF-IDF search()')\n",
        "\t\treturn search(query, k)\n",
        "\tfrom fastembed import TextEmbedding\n",
        "\temb = TextEmbedding('BAAI/bge-small-en-v1.5')\n",
        "\tqv = np.array(list(emb.embed([query]))[0], dtype=np.float32)\n",
        "\t# cosine similarity\n",
        "\tqv = qv / (np.linalg.norm(qv) + 1e-9)\n",
        "\tEv = E / (np.linalg.norm(E, axis=1, keepdims=True) + 1e-9)\n",
        "\tscores = Ev @ qv\n",
        "\tidxs = scores.argsort()[-k:][::-1]\n",
        "\tresults = []\n",
        "\tfor idx in idxs:\n",
        "\t\tchunk_id = emb_records[idx]['chunk_id']\n",
        "\t\tc = next(c for c in chunks if c['chunk_id'] == chunk_id)\n",
        "\t\tresults.append({\n",
        "\t\t\t'score': float(scores[idx]),\n",
        "\t\t\t'document_id': c['parent_document_id'],\n",
        "\t\t\t'page_num': c['page_num'],\n",
        "\t\t\t'section_path': c['section_path'],\n",
        "\t\t\t'snippet': c['text'][:240] + ('...' if len(c['text'])>240 else '')\n",
        "\t\t})\n",
        "\treturn results\n",
        "\n",
        "# Demo\n",
        "for r in search_embedded('energy savings tips'):\n",
        "\tprint(r['score'], r['document_id'], f\"page {r['page_num']}\")\n",
        "\tprint(r['snippet'])\n",
        "\tprint('---')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4048466114956216 emx:visual_extraction:6a55e73ff2d9 page 1\n",
            "Your top three tailored energy-saving tips Caulk windows and doors Upgrade your refrigerator Adjust thermostat settings Save money and energy Look for an Energy Star label Biggest energy saving option One of the biggest Older model Set your...\n",
            "---\n",
            "0.12844813733286536 emx:visual_extraction:6a55e73ff2d9 page 0\n",
            "Home Energy Report: electricity March report Account number: 954137 Service address: 1627 Tulip Lane Dear JILL DOE, here is your usage analysis for March. Your electric use: 18% more than similar nearby homes You TT A bove Similar nearby ho...\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "def search(query: str, k: int = 3):\n",
        "\tqv = vectorizer.transform([query])\n",
        "\tscores = cosine_similarity(qv, X)[0]\n",
        "\ttopk = scores.argsort()[::-1][:k]\n",
        "\tresults = []\n",
        "\tfor idx in topk:\n",
        "\t\tc = chunks[idx]\n",
        "\t\tresults.append({\n",
        "\t\t\t'score': float(scores[idx]),\n",
        "\t\t\t'document_id': c['parent_document_id'],\n",
        "\t\t\t'page_num': c['page_num'],\n",
        "\t\t\t'section_path': c['section_path'],\n",
        "\t\t\t'snippet': c['text'][:240] + ('...' if len(c['text'])>240 else '')\n",
        "\t\t})\n",
        "\treturn results\n",
        "\n",
        "for r in search('energy savings tips'):\n",
        "\tprint(r['score'], r['document_id'], f\"page {r['page_num']}\")\n",
        "\tprint(r['snippet'])\n",
        "\tprint('---')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Ingest current run into Postgres (Phase 5)\n",
        "This cell applies the migration and ingests documents, chunks, and embeddings into Postgres using `DATABASE_URL`. Requires pgvector extension installed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using DATABASE_URL\n",
            "Applying migration 001_init.sql\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "psql:/root/Programming Projects/Personal/EcoMetricx/db/migrations/001_init.sql:2: ERROR:  extension \"vector\" is not available\n",
            "DETAIL:  Could not open extension control file \"/usr/share/postgresql/17/extension/vector.control\": No such file or directory.\n",
            "HINT:  The extension must first be installed on the system where PostgreSQL is running.\n",
            "psql:/root/Programming Projects/Personal/EcoMetricx/db/migrations/001_init.sql:21: NOTICE:  relation \"documents\" already exists, skipping\n",
            "psql:/root/Programming Projects/Personal/EcoMetricx/db/migrations/001_init.sql:40: NOTICE:  relation \"chunks\" already exists, skipping\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CREATE TABLE\n",
            "CREATE TABLE\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "psql:/root/Programming Projects/Personal/EcoMetricx/db/migrations/001_init.sql:48: ERROR:  type \"vector\" does not exist\n",
            "LINE 4:   embedding VECTOR(384) NOT NULL\n",
            "                    ^\n",
            "psql:/root/Programming Projects/Personal/EcoMetricx/db/migrations/001_init.sql:52: NOTICE:  column \"text_tsv\" of relation \"chunks\" already exists, skipping\n",
            "psql:/root/Programming Projects/Personal/EcoMetricx/db/migrations/001_init.sql:54: NOTICE:  relation \"idx_chunks_text_tsv\" already exists, skipping\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ALTER TABLE\n",
            "CREATE INDEX\n",
            "CREATE FUNCTION\n",
            "DROP TRIGGER\n",
            "CREATE TRIGGER\n",
            "Ingesting current run...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "psql:/root/Programming Projects/Personal/EcoMetricx/db/migrations/001_init.sql:77: ERROR:  relation \"chunk_embeddings\" does not exist\n",
            "CONTEXT:  SQL statement \"CREATE INDEX IF NOT EXISTS idx_chunk_embeddings_ivf ON chunk_embeddings USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100)\"\n",
            "PL/pgSQL function inline_code_block line 6 at EXECUTE\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Ingested documents and chunks (FTS-only)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Ingest to Postgres using DATABASE_URL\n",
        "import os\n",
        "from importlib import util as _iu\n",
        "\n",
        "# Ensure psycopg and dotenv available in kernel\n",
        "missing = []\n",
        "for m in ('psycopg', 'dotenv'):\n",
        "\tif _iu.find_spec(m) is None:\n",
        "\t\tmissing.append(m)\n",
        "if missing:\n",
        "\tprint('Installing missing packages:', missing)\n",
        "\t_ = subprocess.run([sys.executable, '-m', 'pip', 'install', *missing, '--quiet'], text=True)\n",
        "\n",
        "# Apply migration (requires psql available). Skip if not present.\n",
        "DATABASE_URL = os.environ.get('DATABASE_URL') or os.environ.get('POSTGRES_DSN')\n",
        "if DATABASE_URL:\n",
        "\tprint('Using DATABASE_URL')\n",
        "\t# Best effort migration via psql if available\n",
        "\tpsql = subprocess.run(['which', 'psql'], capture_output=True, text=True)\n",
        "\tif psql.returncode == 0:\n",
        "\t\tprint('Applying migration 001_init.sql')\n",
        "\t\t_ = subprocess.run(['psql', DATABASE_URL, '-f', str(project_root / 'db' / 'migrations' / '001_init.sql')], text=True)\n",
        "\telse:\n",
        "\t\tprint('psql not found; please apply db/migrations/001_init.sql manually')\n",
        "\t# Ingest\n",
        "\tprint('Ingesting current run...')\n",
        "\tret = subprocess.run([sys.executable, str(project_root / 'scripts' / 'ingest_to_postgres.py')], capture_output=True, text=True)\n",
        "\tprint(ret.stdout or ret.stderr)\n",
        "else:\n",
        "\tprint('DATABASE_URL not set; skipping ingestion')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Call the Retrieval API (optional)\n",
        "This cell demonstrates calling the local FastAPI service (`/search`). Set `API_KEY` to your generated key and ensure the server is running.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API call failed: HTTPConnectionPool(host='127.0.0.1', port=8000): Max retries exceeded with url: /search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc9611347d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
          ]
        }
      ],
      "source": [
        "import os, requests, json as _json\n",
        "API_HOST = os.environ.get('API_HOST', 'http://127.0.0.1:8000')\n",
        "API_KEY = os.environ.get('API_KEY', 'REPLACE_THIS')  # replace with your key\n",
        "\n",
        "payload = {\"query\": \"energy savings tips\", \"k\": 3}\n",
        "headers = {\"X-API-Key\": API_KEY, \"Content-Type\": \"application/json\"}\n",
        "try:\n",
        "\tresp = requests.post(f\"{API_HOST}/search\", headers=headers, data=_json.dumps(payload), timeout=10)\n",
        "\tprint(resp.status_code)\n",
        "\tprint(resp.json())\n",
        "except Exception as e:\n",
        "\tprint('API call failed:', e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load .env for DB ingestion\n",
        "Set environment variables from your `.env` so the ingestion cell can read `DATABASE_URL`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded .env: True\n",
            "DATABASE_URL set: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "\tfrom dotenv import load_dotenv\n",
        "\texists = load_dotenv()\n",
        "\tprint('Loaded .env:', exists)\n",
        "\tprint('DATABASE_URL set:', bool(os.environ.get('DATABASE_URL')))\n",
        "except Exception as e:\n",
        "\tprint('dotenv not available or failed:', e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Query the Retrieval API from this notebook\n",
        "Set `API_HOST` and `API_KEY` (or keep defaults if you exported them to the environment). The cells below call `/search` and `/similar`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API_HOST: http://127.0.0.1:8000\n",
            "API_KEY set: True\n",
            "API call failed: HTTPConnectionPool(host='127.0.0.1', port=8000): Max retries exceeded with url: /search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc96383d010>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
          ]
        }
      ],
      "source": [
        "import os, json, requests\n",
        "API_HOST = os.environ.get('API_HOST', 'http://127.0.0.1:8000')\n",
        "API_KEY = os.environ.get('API_KEY', '')  # set here if not in env\n",
        "\n",
        "print('API_HOST:', API_HOST)\n",
        "print('API_KEY set:', bool(API_KEY))\n",
        "\n",
        "payload = {\"query\": \"energy savings tips\", \"k\": 3}\n",
        "headers = {\"X-API-Key\": API_KEY, \"Content-Type\": \"application/json\"}\n",
        "try:\n",
        "\tresp = requests.post(f\"{API_HOST}/search\", headers=headers, data=json.dumps(payload), timeout=10)\n",
        "\tprint(resp.status_code)\n",
        "\tprint(resp.json())\n",
        "except Exception as e:\n",
        "\tprint('API call failed:', e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API call failed: HTTPConnectionPool(host='127.0.0.1', port=8000): Max retries exceeded with url: /similar (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc95e575290>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
          ]
        }
      ],
      "source": [
        "similar_payload = {\"chunk_id\": \"emx:visual_extraction:6a55e73ff2d9:c0\", \"k\": 5}\n",
        "headers = {\"X-API-Key\": API_KEY, \"Content-Type\": \"application/json\"}\n",
        "try:\n",
        "\tresp = requests.post(f\"{API_HOST}/similar\", headers=headers, data=json.dumps(similar_payload), timeout=10)\n",
        "\tprint(resp.status_code)\n",
        "\tprint(resp.json())\n",
        "except Exception as e:\n",
        "\tprint('API call failed:', e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive query (type your question)\n",
        "Use the widget below to enter your query and hit Search. Make sure the API server is running and `API_KEY` is set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2706598405240029701dcc370262b2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HBox(children=(Text(value='', description='Query:', placeholder='Type your question...'), IntSlâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os, json, requests\n",
        "from ipywidgets import Text, IntSlider, Button, VBox, HBox, Output\n",
        "from IPython.display import display\n",
        "\n",
        "API_HOST = os.environ.get('API_HOST', 'http://127.0.0.1:8000')\n",
        "API_KEY = os.environ.get('API_KEY', '')\n",
        "\n",
        "q_input = Text(description='Query:', placeholder='Type your question...')\n",
        "k_input = IntSlider(description='Top-K', min=1, max=10, value=3)\n",
        "run_btn = Button(description='Search', button_style='primary')\n",
        "out = Output()\n",
        "\n",
        "headers = {\"X-API-Key\": API_KEY, \"Content-Type\": \"application/json\"}\n",
        "\n",
        "def on_click(_):\n",
        "\tout.clear_output()\n",
        "\tpayload = {\"query\": q_input.value, \"k\": int(k_input.value)}\n",
        "\ttry:\n",
        "\t\tresp = requests.post(f\"{API_HOST}/search\", headers=headers, data=json.dumps(payload), timeout=15)\n",
        "\t\twith out:\n",
        "\t\t\tprint('Status:', resp.status_code)\n",
        "\t\t\tprint(json.dumps(resp.json(), indent=2))\n",
        "\texcept Exception as e:\n",
        "\t\twith out:\n",
        "\t\t\tprint('API call failed:', e)\n",
        "\n",
        "run_btn.on_click(on_click)\n",
        "\n",
        "display(VBox([HBox([q_input, k_input, run_btn]), out]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## API diagnostics and bulk query tests\n",
        "Use these cells to inspect the API config and run a batch of common queries. Start the API and ensure `API_KEY`/`API_HOST` are set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Status: 200\n",
            "{\n",
            "  \"fastembed_ok\": true,\n",
            "  \"qdrant_configured\": true,\n",
            "  \"qdrant_warm\": true,\n",
            "  \"qdrant_points\": 1,\n",
            "  \"documents\": 1,\n",
            "  \"chunks\": 1,\n",
            "  \"tsv_ready\": 1\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import os, json, requests\n",
        "API_HOST = os.environ.get('API_HOST', 'http://127.0.0.1:8000')\n",
        "API_KEY = os.environ.get('API_KEY', '')\n",
        "headers = {\"X-API-Key\": API_KEY, \"Content-Type\": \"application/json\"}\n",
        "\n",
        "# Call the new /debug/config endpoint added by Claude Code\n",
        "try:\n",
        "\tresp = requests.get(f\"{API_HOST}/debug/config\", headers=headers, timeout=10)\n",
        "\tprint('Status:', resp.status_code)\n",
        "\tprint(json.dumps(resp.json(), indent=2))\n",
        "except Exception as e:\n",
        "\tprint('API call failed:', e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: home energy report\n",
            "Status: 200\n",
            "Count: 1\n",
            "{\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"chunk_id\": \"emx:visual_extraction:6a55e73ff2d9:c0\",\n",
            "      \"document_id\": \"emx:visual_extraction:6a55e73ff2d9\",\n",
            "      \"page_num\": 1,\n",
            "      \"score\": 0.7200000400000001,\n",
            "      \"snippet\": \"Your top three tailored energy-saving tips Caulk windows and doors Upgrade your refrigerator Adjust thermostat settings Save money and energy Look for an Energy Star label Biggest energy saving option One of the biggest Older model Set your smart \\\\ money-wasters in | refrigerators are thermostat to ...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "------------------------------------------------------------\n",
            "Query: energy savings tips\n",
            "Status: 200\n",
            "Count: 1\n",
            "{\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"chunk_id\": \"emx:visual_extraction:6a55e73ff2d9:c0\",\n",
            "      \"document_id\": \"emx:visual_extraction:6a55e73ff2d9\",\n",
            "      \"page_num\": 1,\n",
            "      \"score\": 0.04529914560000001,\n",
            "      \"snippet\": \"Your top three tailored energy-saving tips Caulk windows and doors Upgrade your refrigerator Adjust thermostat settings Save money and energy Look for an Energy Star label Biggest energy saving option One of the biggest Older model Set your smart \\\\ money-wasters in | refrigerators are thermostat to ...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "------------------------------------------------------------\n",
            "Query: monthly savings tip\n",
            "Status: 200\n",
            "Count: 1\n",
            "{\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"chunk_id\": \"emx:visual_extraction:6a55e73ff2d9:c0\",\n",
            "      \"document_id\": \"emx:visual_extraction:6a55e73ff2d9\",\n",
            "      \"page_num\": 1,\n",
            "      \"score\": 0.4,\n",
            "      \"snippet\": \"Your top three tailored energy-saving tips Caulk windows and doors Upgrade your refrigerator Adjust thermostat settings Save money and energy Look for an Energy Star label Biggest energy saving option One of the biggest Older model Set your smart \\\\ money-wasters in | refrigerators are thermostat to ...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "------------------------------------------------------------\n",
            "Query: thermostat settings advice\n",
            "Status: 200\n",
            "Count: 1\n",
            "{\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"chunk_id\": \"emx:visual_extraction:6a55e73ff2d9:c0\",\n",
            "      \"document_id\": \"emx:visual_extraction:6a55e73ff2d9\",\n",
            "      \"page_num\": 1,\n",
            "      \"score\": 0.16000000000000003,\n",
            "      \"snippet\": \"Your top three tailored energy-saving tips Caulk windows and doors Upgrade your refrigerator Adjust thermostat settings Save money and energy Look for an Energy Star label Biggest energy saving option One of the biggest Older model Set your smart \\\\ money-wasters in | refrigerators are thermostat to ...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "------------------------------------------------------------\n",
            "Query: caulk windows doors\n",
            "Status: 200\n",
            "Count: 1\n",
            "{\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"chunk_id\": \"emx:visual_extraction:6a55e73ff2d9:c0\",\n",
            "      \"document_id\": \"emx:visual_extraction:6a55e73ff2d9\",\n",
            "      \"page_num\": 1,\n",
            "      \"score\": 0.025,\n",
            "      \"snippet\": \"Your top three tailored energy-saving tips Caulk windows and doors Upgrade your refrigerator Adjust thermostat settings Save money and energy Look for an Energy Star label Biggest energy saving option One of the biggest Older model Set your smart \\\\ money-wasters in | refrigerators are thermostat to ...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "------------------------------------------------------------\n",
            "Query: upgrade refrigerator\n",
            "Status: 200\n",
            "Count: 1\n",
            "{\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"chunk_id\": \"emx:visual_extraction:6a55e73ff2d9:c0\",\n",
            "      \"document_id\": \"emx:visual_extraction:6a55e73ff2d9\",\n",
            "      \"page_num\": 1,\n",
            "      \"score\": 0.020000000000000004,\n",
            "      \"snippet\": \"Your top three tailored energy-saving tips Caulk windows and doors Upgrade your refrigerator Adjust thermostat settings Save money and energy Look for an Energy Star label Biggest energy saving option One of the biggest Older model Set your smart \\\\ money-wasters in | refrigerators are thermostat to ...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "------------------------------------------------------------\n",
            "Query: usage compared similar homes\n",
            "Status: 200\n",
            "Count: 1\n",
            "{\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"chunk_id\": \"emx:visual_extraction:6a55e73ff2d9:c0\",\n",
            "      \"document_id\": \"emx:visual_extraction:6a55e73ff2d9\",\n",
            "      \"page_num\": 1,\n",
            "      \"score\": 0.4,\n",
            "      \"snippet\": \"Your top three tailored energy-saving tips Caulk windows and doors Upgrade your refrigerator Adjust thermostat settings Save money and energy Look for an Energy Star label Biggest energy saving option One of the biggest Older model Set your smart \\\\ money-wasters in | refrigerators are thermostat to ...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "------------------------------------------------------------\n",
            "Query: march report\n",
            "Status: 200\n",
            "Count: 1\n",
            "{\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"chunk_id\": \"emx:visual_extraction:6a55e73ff2d9:c0\",\n",
            "      \"document_id\": \"emx:visual_extraction:6a55e73ff2d9\",\n",
            "      \"page_num\": 1,\n",
            "      \"score\": 0.04000000000000001,\n",
            "      \"snippet\": \"Your top three tailored energy-saving tips Caulk windows and doors Upgrade your refrigerator Adjust thermostat settings Save money and energy Look for an Energy Star label Biggest energy saving option One of the biggest Older model Set your smart \\\\ money-wasters in | refrigerators are thermostat to ...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "------------------------------------------------------------\n",
            "Non-empty queries: 8 / 8\n"
          ]
        }
      ],
      "source": [
        "# Bulk query test using the updated fusion logic\n",
        "queries = [\n",
        "\t\"home energy report\",\n",
        "\t\"energy savings tips\",\n",
        "\t\"monthly savings tip\",\n",
        "\t\"thermostat settings advice\",\n",
        "\t\"caulk windows doors\",\n",
        "\t\"upgrade refrigerator\",\n",
        "\t\"usage compared similar homes\",\n",
        "\t\"march report\",\n",
        "]\n",
        "\n",
        "non_empty = 0\n",
        "for q in queries:\n",
        "\tpayload = {\"query\": q, \"k\": 5}\n",
        "\tresp = requests.post(f\"{API_HOST}/search\", headers=headers, data=json.dumps(payload), timeout=15)\n",
        "\tprint(f\"Query: {q}\")\n",
        "\tprint('Status:', resp.status_code)\n",
        "\ttry:\n",
        "\t\tres = resp.json()\n",
        "\t\tprint('Count:', len(res.get('results', [])))\n",
        "\t\tif res.get('results'):\n",
        "\t\t\tnon_empty += 1\n",
        "\t\tprint(json.dumps(res, indent=2))\n",
        "\texcept Exception:\n",
        "\t\tprint(resp.text)\n",
        "\tprint('-' * 60)\n",
        "\n",
        "print('Non-empty queries:', non_empty, '/', len(queries))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pdf-extractor",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
